---
title: "Niveau Exp√©riment√©"
subtitle: "IA de Pointe, MLOps et Production"
date: last-modified
format:
  html:
    toc: true
    toc-depth: 3
---

## üíé Bienvenue au Niveau Exp√©riment√©

Vous ma√Ætrisez le machine learning et le deep learning ? Explorez maintenant l'√©tat de l'art : transformers, IA g√©n√©rative, MLOps, et d√©ploiement en production.

## ü§ñ Module 1 : Architectures Avanc√©es

### Transformers et Attention

Les transformers ont r√©volutionn√© le NLP et au-del√†.

```python
from transformers import (
    AutoTokenizer, AutoModel,
    AutoModelForSequenceClassification,
    Trainer, TrainingArguments
)

# Charger un mod√®le pr√©-entra√Æn√©
model_name = "camembert-base"  # Mod√®le fran√ßais
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(
    model_name,
    num_labels=2
)

# Tokenisation
inputs = tokenizer(
    "Votre texte ici",
    padding=True,
    truncation=True,
    return_tensors="pt"
)

# Pr√©diction
outputs = model(**inputs)
predictions = outputs.logits.argmax(dim=-1)
```

### Fine-tuning de Mod√®les Pr√©-entra√Æn√©s

```python
from transformers import TrainingArguments, Trainer

# Configuration de l'entra√Ænement
training_args = TrainingArguments(
    output_dir="./results",
    num_train_epochs=3,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=64,
    warmup_steps=500,
    weight_decay=0.01,
    logging_dir='./logs',
    evaluation_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True
)

# Cr√©er le trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    tokenizer=tokenizer
)

# Entra√Æner
trainer.train()
```

### Vision Transformers (ViT)

Transformers appliqu√©s √† la vision par ordinateur.

```python
from transformers import ViTForImageClassification, ViTImageProcessor

# Charger le mod√®le
processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')
model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')

# Pr√©parer l'image
inputs = processor(images=image, return_tensors="pt")

# Pr√©diction
outputs = model(**inputs)
logits = outputs.logits
predicted_class = logits.argmax(-1).item()
```

## üé® Module 2 : IA G√©n√©rative

### Diffusion Models

```python
from diffusers import StableDiffusionPipeline
import torch

# Charger Stable Diffusion
pipe = StableDiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16
)
pipe = pipe.to("cuda")

# G√©n√©rer une image
prompt = "A beautiful landscape with mountains and a lake"
image = pipe(prompt, num_inference_steps=50).images[0]
image.save("generated_image.png")
```

### Large Language Models (LLM)

```python
from transformers import pipeline

# G√©n√©ration de texte
generator = pipeline('text-generation', model='gpt2-large')
generated = generator(
    "L'intelligence artificielle va",
    max_length=100,
    num_return_sequences=3,
    temperature=0.8
)

for i, text in enumerate(generated):
    print(f"Version {i+1}: {text['generated_text']}")
```

### Retrieval-Augmented Generation (RAG)

```python
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA
from langchain.llms import HuggingFacePipeline

# Cr√©er une base de connaissances vectorielle
embeddings = HuggingFaceEmbeddings()
vectorstore = FAISS.from_texts(documents, embeddings)

# Cr√©er le syst√®me RAG
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=vectorstore.as_retriever(),
    return_source_documents=True
)

# Poser une question
result = qa_chain({"query": "Qu'est-ce que l'IA g√©n√©rative ?"})
```

## üîß Module 3 : MLOps et Production

### Tracking d'Exp√©riences

```python
import mlflow
import mlflow.sklearn

# D√©marrer MLflow
mlflow.set_experiment("my_experiment")

with mlflow.start_run():
    # Logger les param√®tres
    mlflow.log_param("n_estimators", 100)
    mlflow.log_param("max_depth", 10)
    
    # Entra√Æner le mod√®le
    model = RandomForestClassifier(n_estimators=100, max_depth=10)
    model.fit(X_train, y_train)
    
    # Logger les m√©triques
    accuracy = model.score(X_test, y_test)
    mlflow.log_metric("accuracy", accuracy)
    
    # Logger le mod√®le
    mlflow.sklearn.log_model(model, "model")
```

### Containerisation avec Docker

```dockerfile
# Dockerfile pour une API ML
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8000

CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000"]
```

### API REST avec FastAPI

```python
from fastapi import FastAPI
from pydantic import BaseModel
import joblib
import numpy as np

app = FastAPI()

# Charger le mod√®le
model = joblib.load('model.pkl')

class PredictionInput(BaseModel):
    features: list[float]

class PredictionOutput(BaseModel):
    prediction: float
    probability: float

@app.post("/predict", response_model=PredictionOutput)
async def predict(input_data: PredictionInput):
    # Pr√©parer les donn√©es
    X = np.array(input_data.features).reshape(1, -1)
    
    # Pr√©diction
    prediction = model.predict(X)[0]
    probability = model.predict_proba(X)[0].max()
    
    return PredictionOutput(
        prediction=float(prediction),
        probability=float(probability)
    )

@app.get("/health")
async def health():
    return {"status": "healthy"}
```

### CI/CD pour ML

```yaml
# .github/workflows/ml-pipeline.yml
name: ML Pipeline

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  train:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.9
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Train model
        run: python train.py
      
      - name: Test model
        run: python test.py
      
      - name: Upload model artifact
        uses: actions/upload-artifact@v2
        with:
          name: trained-model
          path: model.pkl
```

## üìä Module 4 : Monitoring et Observabilit√©

### D√©tection de Data Drift

```python
from evidently.report import Report
from evidently.metric_preset import DataDriftPreset
import pandas as pd

# Comparer donn√©es d'entra√Ænement et production
reference_data = pd.read_csv('train_data.csv')
current_data = pd.read_csv('production_data.csv')

# Cr√©er le rapport
report = Report(metrics=[
    DataDriftPreset()
])

report.run(
    reference_data=reference_data,
    current_data=current_data
)

report.save_html('drift_report.html')
```

### Monitoring des Performances

```python
from prometheus_client import Counter, Histogram, start_http_server
import time

# M√©triques Prometheus
prediction_counter = Counter('predictions_total', 'Total predictions made')
prediction_duration = Histogram('prediction_duration_seconds', 'Prediction duration')

@prediction_duration.time()
def make_prediction(data):
    prediction = model.predict(data)
    prediction_counter.inc()
    return prediction

# D√©marrer le serveur de m√©triques
start_http_server(8001)
```

## üß™ Module 5 : Techniques Avanc√©es

### Federated Learning

Apprentissage distribu√© pr√©servant la confidentialit√©.

```python
import syft as sy
import torch

# Configuration Federated Learning
hook = sy.TorchHook(torch)
alice = sy.VirtualWorker(hook, id="alice")
bob = sy.VirtualWorker(hook, id="bob")

# Distribuer les donn√©es
data_alice = data[:len(data)//2].send(alice)
data_bob = data[len(data)//2:].send(bob)

# Entra√Ænement f√©d√©r√©
for epoch in range(epochs):
    for worker_data in [data_alice, data_bob]:
        model.send(worker_data.location)
        # Entra√Æner localement
        loss = train_step(model, worker_data)
        model.get()
```

### AutoML

```python
from autogluon.tabular import TabularPredictor

# AutoML avec AutoGluon
predictor = TabularPredictor(
    label='target',
    eval_metric='roc_auc',
    problem_type='binary'
)

# Entra√Ænement automatique
predictor.fit(
    train_data,
    time_limit=3600,  # 1 heure
    presets='best_quality'
)

# Pr√©dictions
predictions = predictor.predict(test_data)
leaderboard = predictor.leaderboard()
```

### Neural Architecture Search (NAS)

```python
import keras_tuner as kt

def build_model(hp):
    model = keras.Sequential()
    
    # Optimiser le nombre de couches
    for i in range(hp.Int('num_layers', 1, 5)):
        model.add(layers.Dense(
            units=hp.Int(f'units_{i}', 32, 512, step=32),
            activation='relu'
        ))
        
        if hp.Boolean(f'dropout_{i}'):
            model.add(layers.Dropout(hp.Float(f'dropout_rate_{i}', 0.1, 0.5)))
    
    model.add(layers.Dense(num_classes, activation='softmax'))
    
    # Optimiser le learning rate
    model.compile(
        optimizer=keras.optimizers.Adam(hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    
    return model

# Recherche d'architecture
tuner = kt.Hyperband(
    build_model,
    objective='val_accuracy',
    max_epochs=50,
    directory='nas_results',
    project_name='architecture_search'
)

tuner.search(X_train, y_train, epochs=50, validation_split=0.2)
```

## üõ°Ô∏è Module 6 : IA Responsable

### D√©tection de Biais

```python
from aif360.datasets import BinaryLabelDataset
from aif360.metrics import BinaryLabelDatasetMetric
from aif360.algorithms.preprocessing import Reweighing

# Cr√©er le dataset
dataset = BinaryLabelDataset(
    df=data,
    label_names=['outcome'],
    protected_attribute_names=['gender', 'race']
)

# Mesurer les biais
metric = BinaryLabelDatasetMetric(
    dataset,
    unprivileged_groups=[{'gender': 0}],
    privileged_groups=[{'gender': 1}]
)

print(f"Disparate Impact: {metric.disparate_impact()}")
print(f"Statistical Parity: {metric.statistical_parity_difference()}")

# Mitigation des biais
rw = Reweighing(
    unprivileged_groups=[{'gender': 0}],
    privileged_groups=[{'gender': 1}]
)
dataset_transf = rw.fit_transform(dataset)
```

### Explainability

```python
from lime import lime_tabular
from alibi.explainers import AnchorTabular

# LIME
explainer = lime_tabular.LimeTabularExplainer(
    X_train,
    feature_names=feature_names,
    class_names=['Class 0', 'Class 1'],
    mode='classification'
)

explanation = explainer.explain_instance(
    X_test[0],
    model.predict_proba,
    num_features=10
)

# Anchor Explanations
anchor_explainer = AnchorTabular(
    predictor=model.predict,
    feature_names=feature_names
)

explanation = anchor_explainer.explain(X_test[0])
```

## üöÄ Projets de Pointe

### Projet 1 : Chatbot Conversationnel

Cr√©er un assistant IA avec RAG et LLM.

**Comp√©tences** : Transformers, RAG, FastAPI, Docker

### Projet 2 : Syst√®me de Recommandation

Syst√®me de recommandation √† grande √©chelle.

**Comp√©tences** : Deep learning, embeddings, MLOps, monitoring

### Projet 3 : Pipeline ML Complet

Pipeline end-to-end avec MLOps.

**Comp√©tences** : CI/CD, monitoring, containerisation, API

## üìö Ressources de Pointe

### Conf√©rences et Publications

- **NeurIPS** : Conf√©rence principale en ML
- **ICML** : International Conference on Machine Learning
- **CVPR** : Computer Vision
- **ACL** : Natural Language Processing
- **arXiv.org** : Pr√©publications de recherche

### Communaut√©s

- **Papers with Code** : Reproduire les derni√®res recherches
- **Hugging Face Hub** : Mod√®les et datasets
- **Kaggle** : Comp√©titions et collaboration

## ‚úÖ Expertise Confirm√©e

Vous ma√Ætrisez le niveau exp√©riment√© si vous pouvez :

- [ ] Fine-tuner des transformers pour vos t√¢ches
- [ ] D√©ployer des mod√®les en production avec MLOps
- [ ] Impl√©menter des pipelines CI/CD pour ML
- [ ] Monitorer et maintenir des mod√®les en production
- [ ] D√©tecter et corriger les biais dans vos mod√®les
- [ ] Appliquer les principes d'IA responsable
- [ ] Suivre et impl√©menter les derni√®res recherches
- [ ] G√©rer des projets ML de bout en bout

---

::: {.callout-note}
## üéì F√©licitations !
Vous avez atteint le niveau expert en IA. Continuez √† explorer, exp√©rimenter et contribuer √† la communaut√© !
:::
